{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "caded33afa80e27ddd392cf31936d682",
     "grade": false,
     "grade_id": "cell-11ef9fbc6790a68b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Regresion Lineal por el metodo de Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9693a553f0b18436ffb9975dee33e728",
     "grade": false,
     "grade_id": "cell-81a16b42de1bb106",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Los modelos predictivos de Scikit-learn se definen como clases que tienen al menos cuatro métodos:\n",
    "* ``__init__``: el constructor, recibe como argumentos los meta-parámetros del modelo y los almacena\n",
    "* ``fit``: recibe como argumentos X e y, entrena el modelo (calcula sus parámetros) y lo devuelve.\n",
    "* ``predict``: recibe como argumento X, calcula las predicciones y las devuelve.\n",
    "* ``score``: recibe como argumentos X e y, realiza las predicciones sobre X y calcula con ellas el error de aproximación a y. Por defecto aplica la métrica ``r2_score`` a los modelos de regresión y la métrica ``accuracy`` a los de clasifiación.\n",
    "\n",
    "Programa a continuación los métodos fit y predict de la regresión lineal mediante el método de Ordinary Least Squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "de251aef75455bf4d179638a0200063f",
     "grade": false,
     "grade_id": "cell-c40d4400f0cdd222",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class OLSLinearRegression(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return r2_score(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d833e0e183bdfddcd2b1cb88988d975",
     "grade": false,
     "grade_id": "cell-dcc5eef402a0a268",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La regresión lineal con el método de OLS ya está disponible en Scikit-learn mediante la clase ``LinearRegression`` del submódulo ``linear_model``. Si has programado el método de OLS correctamente, debería producir los mismos resultados que ``LinearRegression`` sobre los datasets de regresión de Boston Housing y Diabetes, que se obtienen con las funciones de Scikit-learn ``load_boston`` y ``load_diabetes``, respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab483a58b5e88d18a26e37e1bc40f41f",
     "grade": true,
     "grade_id": "cell-de1ef339d923b5a4",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for loader in (load_boston, load_diabetes):\n",
    "    X, y = loader(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    ols_lr = OLSLinearRegression()\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    ols_lr.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    ols_lr_preds = ols_lr.predict(X_test)\n",
    "    lr_preds = lr.predict(X_test)\n",
    "    np.testing.assert_array_almost_equal(ols_lr_preds, lr_preds, decimal=3, err_msg='Las predicciones difieren demasiado')\n",
    "\n",
    "    ols_lr_score = ols_lr.score(X_test, y_test)\n",
    "    lr_score = lr.score(X_test, y_test)\n",
    "    print(loader.__name__ + ':\\n\\tR2 OLS: ' + str(ols_lr_score) + '\\n\\tR2 LS: ' + str(lr_score))\n",
    "    np.testing.assert_almost_equal(ols_lr_score, lr_score, decimal=2, err_msg='Los scores difieren demasiado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e41991d49bd04fc501fbb2ce8f18b71d",
     "grade": false,
     "grade_id": "cell-030361b0cc95b0c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Regresion Lineal por el metodo de Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03e88b3d1f9b67d8f7574d47755b02dc",
     "grade": false,
     "grade_id": "cell-6961e2703cad8fca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "En esta ocasión debes implementar los métodos ``fit`` y ``predict`` de la regresión lineal mediante el método de descenso por gradiente estocástico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7e5370000b89c24fad676b754fa47813",
     "grade": false,
     "grade_id": "cell-070c6b1570479dc6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "class SGDLinearRegression(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, max_iter=1000, eta=0.01):\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return r2_score(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1dfe18a5d7d42972b7457bbfbf196efa",
     "grade": false,
     "grade_id": "cell-c0dd66c08a4fb10f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Se puede comprobar si los resultados son similares a los obtenidos con el modelo ``SGDRegressor`` de Scikit-learn. En este caso hay que tomar la precaución de estandarizar los datos de entrada, ya que los métodos basados en descenso por gradiente son sensibles a la escala de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b0de87f052f65522ea4b215c2751b5d",
     "grade": true,
     "grade_id": "cell-19548a2262e25af5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_diabetes\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for loader in (load_boston, load_diabetes):\n",
    "    X, y = loader(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    sgd_lr = Pipeline([('stds', StandardScaler()), ('sgd_lr', SGDLinearRegression())])\n",
    "    sgd = Pipeline([('stds', StandardScaler()), ('sgd', SGDRegressor(penalty=None, shuffle=False, learning_rate='constant'))])\n",
    "\n",
    "    sgd_lr.fit(X_train, y_train)\n",
    "    sgd.fit(X_train, y_train)\n",
    "\n",
    "    sgd_lr_score = sgd_lr.score(X_test, y_test)\n",
    "    sgd_score = sgd.score(X_test, y_test)\n",
    "    print(loader.__name__ + ':\\n\\tR2 SGDLR: ' + str(sgd_lr_score) + '\\n\\tR2 SGDR: ' + str(sgd_score))\n",
    "    np.testing.assert_almost_equal(sgd_lr_score, sgd_score, decimal=1, err_msg='Los scores difieren demasiado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0626d308ab32bce16f78bf052e3e9ec0",
     "grade": false,
     "grade_id": "cell-c9491d770b813f0a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Boston Housing con redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ddcf6baa00c83029c7d54d660e20340",
     "grade": false,
     "grade_id": "cell-59b0f3d543b9c3e7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Una vez entendidos los modelos lineales, estamos en condiciones de probar otros modelos más expresivos como las redes neuronales. Vamos a comprobar su efectividad con un conjunto de datos clásico en Aprendizaje Automático: Boston Housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "be58f5d178a3c86a27189f303b230437",
     "grade": false,
     "grade_id": "cell-5478d66d95ac46fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "El dataset está disponible en la página web de UCI (https://archive.ics.uci.edu/ml/datasets/Housing), donde, aparte de descargarlo, podéis ver el tipo de variables que contiene, que es un dataset de regresión, y algunos detalles más. Por suerte para nosotros, scikit-learn ya dispone de una función que carga los datos de este dataset en nuestro espacio de trabajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0207a56819185fbb90e657f4cc48dc22",
     "grade": false,
     "grade_id": "cell-c879c4cbd4abc5cd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)\n",
    "print(str(boston.data[0]))\n",
    "print(str(boston.target[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa99549157be64c34f9f501505ca3531",
     "grade": false,
     "grade_id": "cell-6d3dabef794e1bc7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Para poder evaluar de forma fiable los modelos, lo primero que deberíamos hacer es definir folds para cross-validation o separar una parte de los datos como conjunto de test, por ejemplo un 10% de la muestra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b4b0e4ca93bc8f178befa0c9f3d4c3ff",
     "grade": false,
     "grade_id": "cell-e826877ea7697abe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9e1e6eb2d90aceeca38df35841939dd1",
     "grade": false,
     "grade_id": "cell-813a9c7253764fc9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "A continuación, vamos a crear el modelo base contra el que comparar nuestras redes neuronales. Dado que el problema es de regresión, lo más básico que podemos utilizar es una regresión lineal. Usaremos la ya vista anteriormente, que se entrena mediante descenso por gradiente. Estos modelos, así como los de redes neuronales, necesitan una estandarización previa de los datos, por lo que vamos a construir un pipeline de procesamiento en el que la primera componente será un estandarizador y la segunda el modelo predictivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9cbba028f97127572a4692de27b2359c",
     "grade": false,
     "grade_id": "cell-96a87eed3b9abe16",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "estimator = Pipeline([('standardizer', StandardScaler()), ('predictor', SGDRegressor())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d52f0af341282ecf1f1311e75643bd8e",
     "grade": false,
     "grade_id": "cell-26617082808022e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ahora podemos entrenar nuestro modelo con el conjunto de datos de entrenamiento y evaluarlo con el conjunto de datos de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b6df4dc782556477200f461b66aa2dad",
     "grade": false,
     "grade_id": "cell-d1f38d9db2aaa61f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "print(estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c030d65c7184443bcf2b8f4e448e9e71",
     "grade": false,
     "grade_id": "cell-1ca9832d0ef4fbca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "El resultado es mejorable, pero ya tenemos nuestro modelo base contra el que comparar. ¿Serías capaz de programar el mismo pipeline utilizando un perceptrón en lugar de una regresión lineal? La clase de scikit-learn que debes usar es sklearn.neural_network.MLPRegressor. Ten en cuenta que el número y tamaño de las capas ocultas se especifica con el meta-parámetro hidden_layer_sizes (por ejemplo, hidden_layer_sizes=() para un perceptrón simple y hidden_layer_sizes=(100, 100) para un perceptrón con dos capas ocultas de tamaño 100). Es probable que el modelo necesite muchas iteraciones de entrenamiento para converger. Puedes indicar el número máximo de iteraciones con el meta-parámetro max_iter (por ejemplo, max_iter=1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "61cc44617b8c7434093f8cd7a65ec46a",
     "grade": true,
     "grade_id": "cell-c384022c33a522bb",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a47cbcbc7211f4ca437dfd751f5b4f2d",
     "grade": false,
     "grade_id": "cell-72b6dec298ac3748",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Hay modelos que pueden mejorarse a través de términos de regularización. La regresión lineal se puede regularizar con un término L2, lo que nos da el modelo de regresión ridge. Las redes neuronales son los modelos más flexibles en este sentido. Vamos a ver cómo funciona un modelo ridge. Debemos especificar el coeficiente de regularización en el meta-parámetro alpha. Los valores razonables suelen estar entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d3bd99d7d87eb52b3abb8c02a13735a5",
     "grade": false,
     "grade_id": "cell-dffcb882861a4db7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "estimator = Pipeline([('standardizer', StandardScaler()), ('predictor', Ridge(alpha=0.5))])\n",
    "estimator.fit(X_train, y_train)\n",
    "print(estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d70b3c8d6a560a18a8de31e6e6f0d073",
     "grade": false,
     "grade_id": "cell-83feef17b06bc8e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "El modelo MLPRegressor también tiene un parámetro alpha. ¿Puedes probar el modelo añadiendo regularización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6541e8f6d59c5e9469d04996df6d1fa8",
     "grade": true,
     "grade_id": "cell-c58ba1d38348c060",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ebd4de3ff2b05e8b9049d5c0cfa57974",
     "grade": false,
     "grade_id": "cell-db3bdbab249d5b17",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Si has elegido bien el valor del coeficiente alpha, habrás visto una ligera mejora en tu modelo. Normalmente la búsqueda de meta-parámetros se automatiza con métodos como la búsqueda en rejilla o la búsqueda aleatoria. Vamos a probar la búsqueda en rejilla con el modelo ridge para su parámetro alpha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d017799e4a6387cd793e7da56860d40",
     "grade": false,
     "grade_id": "cell-3e9f5958efc63632",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = Pipeline([('standardizer', StandardScaler()), ('predictor', Ridge())])\n",
    "search = GridSearchCV(estimator, {'predictor__alpha': [0.0, 0.25, 0.5, 0.75, 1.0]})\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)\n",
    "print(search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d2adac81b25fd862ff9100e52c96205",
     "grade": false,
     "grade_id": "cell-86f055ce407acfef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "¿Puedes hacer lo mismo con el parámetro alpha del perceptrón multicapa? Puedes probar más valores aparte de 0, 0.25, 0.5, 0.75 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "51b28b6140c4f65703138b513a7e7999",
     "grade": true,
     "grade_id": "cell-00ee122f1e9801df",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c801295242f092f5e14c336f3c0b1696",
     "grade": false,
     "grade_id": "cell-560735fa0ae8f956",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Digits con redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4087c4150b20fb5ae78190de7336c450",
     "grade": false,
     "grade_id": "cell-78a74afa439eaaf0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ahora vamos a experimentar con las redes neuronales en el problema Digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c9013b18a48c429174085924c7afc83c",
     "grade": false,
     "grade_id": "cell-42b991d6486c4c5c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La información sobre el dataset se puede encontrar en http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html. Contiene imágenes de 8x8 píxeles de dígitos manuscritos, y el objetivo es clasificarlos correctamente dentro de las categorías de 0 a 9. Podemos descargarlo directamente utilizando scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3b0899996be103b127a0fc8314e4baa8",
     "grade": false,
     "grade_id": "cell-1c20f05319e3e7ec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "print(str(digits.data[0]))\n",
    "print(str(digits.target[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "876e09c701443c4a5396a9e62c6676ec",
     "grade": false,
     "grade_id": "cell-c15b2db595118622",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Podemos ver qué tipo de imágenes hay en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f8ff1c11d15e8196e6b2a6138af1583",
     "grade": false,
     "grade_id": "cell-523bd6ae1120d5d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "num_images = 10\n",
    "for index, image in enumerate(digits.images[:num_images]):\n",
    "    plt.subplot(2, num_images, index + num_images + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "649c9694efa500414058703c4aac0c70",
     "grade": false,
     "grade_id": "cell-8f0ca4a615a0be21",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Como siempre, lo correcto es hacer folds para cross-validation o al menos separar algunos patrones para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "24c0e116cfdcc49a819d0c621d07de28",
     "grade": false,
     "grade_id": "cell-76d5a41e3802cb86",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f65c1a6c4b13c9b350134248339f26f2",
     "grade": false,
     "grade_id": "cell-7e906fee16e875cc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Vamos a probar qué tal resuelve este problema de clasificación un perceptrón simple con alpha=0.1 (http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c47d304105fa0ed1023d639987be9fff",
     "grade": false,
     "grade_id": "cell-a4f11fca4fade282",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "estimator = Pipeline([('standardizer', StandardScaler()), ('predictor', MLPClassifier(hidden_layer_sizes=(), alpha=0.1, max_iter=10000))])\n",
    "estimator.fit(X_train, y_train)\n",
    "print(estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "08d78306b6f116b2ccba1d0cf78aaa66",
     "grade": false,
     "grade_id": "cell-e4357ab70931907d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Scikit-learn está bastante limitado a la hora de experimentar con redes neuronales, ya que no permite crear redes de tipo convolucional o recurrente. Este problema tiene claramente una estructura espacial (los píxeles de cada imagen están colocados de una determinada forma, y su orden es importante), por lo que probablemente una red convolucional sea capaz de mejorar los resultados. Para probar este tipo de modelos, podemos utilizar la librería Keras (https://keras.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a0e5554170b50f601868405fb326ce10",
     "grade": false,
     "grade_id": "cell-913e4d0caf9d9b4e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "input_shape = (1, 8, 8)\n",
    "X_train_keras = X_train.reshape(X_train.shape[0], *input_shape)\n",
    "X_test_keras = X_test.reshape(X_test.shape[0], *input_shape)\n",
    "X_train_keras = X_train_keras.astype('float32')\n",
    "X_test_keras = X_test_keras.astype('float32')\n",
    "X_train_keras /= 16\n",
    "X_test_keras /= 16\n",
    "num_classes = 10\n",
    "y_train_keras = to_categorical(y_train, num_classes)\n",
    "y_test_keras = to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(1, 8, 8)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train_keras, y_train_keras, batch_size=32, epochs=1000, verbose=0, validation_split=0.1)\n",
    "score = model.evaluate(X_test_keras, y_test_keras, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97f81fafed9a479b204e1aa7b4a1cf3a",
     "grade": false,
     "grade_id": "cell-89e31d52eda72466",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "La red convolucional que acabamos de construir tiene únicamente una capa convolucional y una capa \"normal\" (fully-connected, densa). Podemos mejorar los resultados modificándola para que tenga dos capas convolucionales seguidas de dos capas densas. ¿Puedes hacerlo? Ten en cuenta que hay que controlar el tamaño de los kernels de las convoluciones (en este caso usamos (2, 2). Puedes ver documentación al respecto en http://deeplearning.net/tutorial/lenet.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d608309fc170429036c3c0bbb76a68a0",
     "grade": true,
     "grade_id": "cell-1220ab486f8a68d9",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
